1、GAN是一个框架，不绑定到具体的算法模型，也就是生成器和判别器可以用不同的算法模型，应该是差不多是一个函数拟合器就行了，目前的MLP，CNN，Transformer都有了。生成的也不只是图片，可以是多种内容，它是结构化学习。
2、共同学习的一个原因是，对于判别器，判别器要最小化的划出目标图像和其它图像的分界，生成器不断寻找判别器的漏洞来最小化这个边界，如果不这样找漏洞用一般的正负类做分类方法训练，那么判别器的边界很可能就不是最小化的，一般的分类方法举出所有负类。（当然，你用同样的目标用GAN训练的上一个判别器可以重用，但本质上还是用GAN共同训练得出的）。然后，你光让其中一个进化也不行，只让判别器进化，生成器不能找更高级的漏洞，那它本身也进化不了，如果判别器不进化，生成器也只能原地踏步。这里感觉GAN的关键点就是这个判别器共同训练了，这是他比起一般生成器强的原因。
3、关于G的理解，G是一个样本生成器，就像自然环境中生成树叶样本一样，生成器就相当于这个自然环境，还可以把它看成一个分布，注意分布不是一种具体的函数，它是一个比较抽象的东西，大概就是描述样本在样本空间哪里多哪里少的东西。G可不是概率密度函数，也不是分布函数。然后训练过程就约束G生成的样本符合某种分布。

是否可以采用分块合成的方法减小内存消耗
风格迁移里面有这种方法了

# 总结：
StyleGAN2 主要就是解决V1中出现的伪影问题，团队观察到少量生成的图片有明显的水珠，这个水珠也存在于feature map上。导致水珠的原因是 Adain 操作，Adain对每个feature map进行归一化，因此有可能会破坏掉feature之间的信息。emmmm，懵懵懂懂，最重要的是实验证明 当去除Adain的归一化操作后，水珠就消失了，所以Adain就背锅吧。
其它改进点
## No Progressive growth

StyleGAN使用的Progressive growth会有一些缺点，如下图，当人脸向左右偏转的时候，牙齿却没有偏转，即人脸的一些细节如牙齿、眼珠等位置比较固定，没有根据人脸偏转而变化，造成这种现象是因为采用了Progressive growth训练，Progressive growth是先训练低分辨率，等训练稳定后，再加入高一层的分辨率进行训练，训练稳定后再增加分辨率，即每一种分辨率都会去输出结果，这会导致输出频率较高的细节，如下图中的牙齿，而忽视了移动的变化。然后使用跳接解决了这个问题。

## How to project image to latent code
StyleGAN可以做很多有趣的事情，比如style mixing，但是如何混合指定图像的风格呢，而不是随机假图，这就需要得到指定图像的latent code，这个latent code输入到网络中去，能够复原指定图像。

那么如何生成指定图像的 latent code 呢？论文《Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?》讲的很详尽，有兴趣的可以详细阅读。有两种方法可以将图像映射成 latent code，（1）训练一个编码器，编码器输入是图像，输出是隐藏编码，这种方法的优点是速度快，缺点是不能处理训练数据集以外的图片；（2）选一个随机的latent code，输入到预训练好的网络（比如StyleGAN），根据生成图像与目标图像的损失，通过反向传播对latent code进行迭代，这种方法的泛化性很好，但是速度很慢，因为要迭代很多次。

引言：
styleGAn  架构在数据驱动的无条件生成式图像建模中产生了先进的结果。我们公开和分析了它的一些特征伪影，并且提出了对架构和训练方法的改进来解法它们。特别的，我们重新设计了生成器的规范化，重新审视了渐进增长，并且调整生成器来鼓励来鼓励隐变量到图像的映射中的好的条件。（没太懂这句？）除了提高图像质量之外，这种路径长度正则化器还产生了额外的好处，即生成器变得明显更容易反转。这样就可以将生成的图像可靠地归属于特定的网络。此外，我们还可视化了生成器如何很好地利用其输出分辨率，并确定了一个容量问题，激励我们训练更大的模型以获得更多的质量改进。总的来说，我们改进的模型重新定义了无条件图像建模的最先进技术，包括现有的分布质量指标和感知图像质量。

引言：
生成方法产生的图像的分辨率和质量，特别是生成对抗性网络(GAN)[16]，[23,31,5]迅速提高。 目前最先进的高分辨率图像合成方法是StyleGAN[24]，它已被证明在各种数据集上可靠地工作。 我们的工作重点是修复其特征伪影，进一步提高结果质量。

StyleGAN[24]的显著特点是其非常规的生成器架构。映射网络不是只将输入的潜变量z∈Z输入到网络的开始，而是首先将其转换为具有w∈W的中间潜变量。仿射变换然后样式，这个样式可以控制通过自适应实例归一化控制(AdaIN)[21,9,13,8]控制合成网络的层。此外，通过向合成网络提供额外的随机噪声映射来促进随机变化。[24,38]已经证明，该设计使得中间潜空间W比输入潜空间Z具有更少的纠缠。本文中，我们将所有的分析集中在w上，因为从合成网络的角度上看，它是有意义的潜空间。





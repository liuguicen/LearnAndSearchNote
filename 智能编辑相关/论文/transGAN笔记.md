# 简述
使用tranformers 完全不使用cnn的架构
目前transformer有要成为cv领域通用模型的趋势，它已经在分类，检测，分割这些cv领域取得了成功，但是在一些更为困难的cv领域怎么样呢？
处于好奇，作者做了这样的研究，在GAN中抛弃cnn，完全使用transformer结构，取名为TransGAN

它更加的内存友好，在增加分辨率的同时减少嵌入维度，判别器也是基于transformer的

这个架构从数据增强中可以获得很大的增益。

它可以扩展到更大的模型和更高的分辨率。

我们的最优架构和当前最优的模型相比获得了很具有竞争力的结果。

GAN具有臭名昭著的训练不稳定问题，花费了大量的努力用来稳定GAN的训练，比如多个正则化项，更好的损失以及训练技巧等。另一条路径是改进它的架构。

很多研究表明不使用ResNet主干的网络，仍然能行。但是，更为基础的“常识”CNN似乎没有受到挑战-在GAN中使用CNN。一开始的GAN使用全连接，能生成很小的网络。然后DCGAN首先使用CNN，后面几乎所有成功的GAN都使用了CNN。

在cv领域，基于transformer模型在很多任务上超越了基于cnn的模型。
transformer的优势可以总结为如下两条：
1.它具有更强的表示能力，没有认为定义的归纳偏差。对应的是cnn表现出队局部特征的强烈偏见，以及因为滤波器全局共享参数到导致的空间不变性。
1. transformer是架构上通用，概念上简单的，有潜力成为跨领域和跨任务的通用模型。它摆脱了cnn中的常见的点对点的构建模块的形式

我们的模型只基于transformer，与以前的结合transformer与cnn架构有显著区别。

本文面临两个问题：
1、没有将纯transformer应用于GAN的先例，有的只是应用于其他视觉任务的
2、**transformer的训练也是时间冗长，计算花费沉重，数据需求量大的**
应对上述挑战，我们做出了一系列的努力和创新。

最天然的想法是，对每一个输入像素堆叠transformer块，但这在内存和计算代价上是不允许的。替代的，我们采用逐步的一步增加分辨率，一边降低嵌入维度的方式。判别器也是纯transformer的，以图像块为单位而不是像素，建立token。





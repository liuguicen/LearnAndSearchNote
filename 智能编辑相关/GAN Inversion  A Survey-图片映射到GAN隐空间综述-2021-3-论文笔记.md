将图像映射到预训练的GAN模型（比如StyleGAN，BIgGAN)的潜空间，然后便于对真实图像进行编辑，称之为GAN Inversion。它是真实图像智能编辑的关键环节之一。那么这里可以不用StyleGAN等，而使用更小的生成器？？
在网页 github.com/weihaox/awesome-gan-inversion.中我们介绍了相关的方法，数据集和其它信息

最近的研究表明，GANs可以有效地编码中间特征[18]和潜在空间[19]、[20]、[21]中丰富的语义信息，用于图像的生成，这些方法可以通过改变潜在的代码来合成具有各种属性的图像，如老化、表达式和光的方向。 然而，由于潜在空间中缺乏推理功能或编码器，潜在空间中的操作只适用于从GAN生成的图像，而不是任何给定的真实图像编码器。GAN Inversion使在现有训练好的GAN的发现的潜在空间中的可以用于控制生成结果的方向能适用于真实的图像编辑，而不需要特别的监督或昂贵的优化。这个技术不但帮助编辑真实图像，还帮助解释GAN的生成机理。

映射方法：
还是那三种，基于学习的，基于优化的，两者混合的
基于学习的编码器常见结构是除了最后一层，其它和判别器D相同，基于学习的通常由于直接优化的，并且不会掉入局部最优。
这篇文章似乎不太行，提出这三种方法居然连个比较都没有，你倒是说说它们在速度，空间各方面的比较呀？？？